apiVersion: apps/v1
kind: Deployment
metadata:
  name: adaptive-lora-api
  labels:
    app: adaptive-lora
    component: api
spec:
  replicas: 2
  selector:
    matchLabels:
      app: adaptive-lora
      component: api
  template:
    metadata:
      labels:
        app: adaptive-lora
        component: api
    spec:
      containers:
        - name: api
          image: adaptive-lora-framework:latest
          ports:
            - containerPort: 8000
              name: http
            - containerPort: 9090
              name: metrics
          env:
            - name: HF_TOKEN
              valueFrom:
                secretKeyRef:
                  name: adaptive-lora-secrets
                  key: hf-token
            - name: WANDB_API_KEY
              valueFrom:
                secretKeyRef:
                  name: adaptive-lora-secrets
                  key: wandb-api-key
            - name: REDIS_URL
              value: "redis://redis-service:6379"
          resources:
            requests:
              memory: "8Gi"
              cpu: "2"
              nvidia.com/gpu: "1"
            limits:
              memory: "32Gi"
              cpu: "8"
              nvidia.com/gpu: "1"
          livenessProbe:
            httpGet:
              path: /live
              port: 8000
            initialDelaySeconds: 60
            periodSeconds: 30
          readinessProbe:
            httpGet:
              path: /ready
              port: 8000
            initialDelaySeconds: 30
            periodSeconds: 10
          volumeMounts:
            - name: model-cache
              mountPath: /root/.cache/huggingface
            - name: adapters
              mountPath: /app/adapters
      volumes:
        - name: model-cache
          persistentVolumeClaim:
            claimName: model-cache-pvc
        - name: adapters
          persistentVolumeClaim:
            claimName: adapters-pvc
      nodeSelector:
        gpu: "true"
      tolerations:
        - key: "nvidia.com/gpu"
          operator: "Exists"
          effect: "NoSchedule"
---
apiVersion: v1
kind: Service
metadata:
  name: adaptive-lora-service
  labels:
    app: adaptive-lora
spec:
  type: ClusterIP
  ports:
    - port: 8000
      targetPort: 8000
      name: http
    - port: 9090
      targetPort: 9090
      name: metrics
  selector:
    app: adaptive-lora
    component: api
---
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: adaptive-lora-hpa
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: adaptive-lora-api
  minReplicas: 2
  maxReplicas: 10
  metrics:
    - type: Resource
      resource:
        name: cpu
        target:
          type: Utilization
          averageUtilization: 70
    - type: Pods
      pods:
        metric:
          name: requests_per_second
        target:
          type: AverageValue
          averageValue: "100"
  behavior:
    scaleDown:
      stabilizationWindowSeconds: 300
      policies:
        - type: Percent
          value: 10
          periodSeconds: 60
    scaleUp:
      stabilizationWindowSeconds: 0
      policies:
        - type: Percent
          value: 100
          periodSeconds: 15
